from flask import Flask, jsonify, request, redirect, url_for, session
from google.generativeai import GenerativeModel, configure
from dotenv import load_dotenv
from flask_cors import CORS
from werkzeug.utils import secure_filename
from datetime import datetime
import tempfile
import os
import json
import requests
import pytz
import fitz
import hashlib
import numpy as np

import google.generativeai as genai

from qdrant_client import QdrantClient, models

from flask_dance.contrib.google import make_google_blueprint, google
from flask_dance.consumer import oauth_authorized
from flask_dance.consumer.storage.session import SessionStorage

load_dotenv()

# Configure Gemini API
configure(api_key=os.environ.get("GEMINI_API_KEY"))

app = Flask(__name__)
CORS(app, supports_credentials=True)

os.environ['OAUTHLIB_INSECURE_TRANSPORT'] = '1'
app.secret_key = 'andewalaburger'

# Google OAuth configuration
google_client_id = os.environ.get('GOOGLE_CLIENT_ID')
google_client_secret = os.environ.get('GOOGLE_CLIENT_SECRET')
# Configure Google OAuth with flask-dance
blueprint = make_google_blueprint(
    client_id=google_client_id,
    client_secret=google_client_secret,
    scope=["openid", 
           "https://www.googleapis.com/auth/userinfo.profile", 
           "https://www.googleapis.com/auth/userinfo.email"],
    redirect_to="after_login",  # Where to redirect after authorization
    # Important: Don't set a custom redirect_url unless necessary
)
app.register_blueprint(blueprint, url_prefix="/login")


app.config['UPLOAD_FOLDER'] = tempfile.gettempdir()
qdrant_client = QdrantClient(
    url="https://1c7b5c09-be7f-4b75-b364-a253421756c8.eu-west-1-0.aws.cloud.qdrant.io/", 
    api_key = os.environ.get("QDRANT_API_KEY")  # load this securely from environment
)

# Initialize Gemini models
embedding_model = GenerativeModel("embedding-001")
chat_model = GenerativeModel("gemini-2.0-flash")  # You can also use "gemini-2.0-flash" if available
QDRANT_COLLECTION_NAME='resumes'

# Ensure the Qdrant collection exists
def create_qdrant_collection():
    collections = qdrant_client.get_collections().collections
    if QDRANT_COLLECTION_NAME not in [col.name for col in collections]:
        qdrant_client.create_collection(
            collection_name=QDRANT_COLLECTION_NAME,
            vectors_config=models.VectorParams(size=768, distance=models.Distance.COSINE),  # Gemini embeddings are 768 dimensions
        )

create_qdrant_collection()

def get_all_attendees_qdrant():
    """Get a list of all attendees from Qdrant."""
    points = qdrant_client.scroll(
        collection_name=QDRANT_COLLECTION_NAME,
        scroll_filter=None,
        limit=10000,
        with_payload=True
    )
    user_ids = set()
    for point in points[0]:
        if point.payload and 'user_id' in point.payload:
            user_ids.add(point.payload['user_id'])
    return list(user_ids)

def search_resume_qdrant(query, user_id=None):
    """Search for information in resumes using Qdrant."""
    try:
        # Get embeddings using Gemini instead of OpenAI
        response = embedding_model.embed_content(
            content=query,
            task_type="retrieval_query"
        )
        query_embedding = response.embedding
        
        search_filter = None
        if user_id:
            search_filter = models.Filter(must=[models.FieldCondition(key="user_id", match=models.MatchValue(value=user_id))])

        search_results = qdrant_client.search(
            collection_name=QDRANT_COLLECTION_NAME,
            query_vector=query_embedding,
            query_filter=search_filter,
            limit=5,
            with_payload=True
        )

        results = []
        for hit in search_results:
            payload = hit.payload
            if payload:
                results.append(f"Name: {payload.get('name', 'N/A')}, Summary: {payload.get('text_sample', 'N/A')[:200]}...")
        return "\n".join(results)
    except Exception as e:
        return f"Error searching resumes: {str(e)}"

def get_current_time_ist(_input=None):
        ist = pytz.timezone('Asia/Kolkata')
        now = datetime.now(ist)
        print(now.strftime("%Y-%m-%d %H:%M:%S"))
        return now.strftime("%Y-%m-%d %H:%M:%S")

def submit_feedback_to_google_forms(name, experience, rating):
    print("üî®Tool called: submit_feedback_to_google_forms")
    form_post_url = 'https://docs.google.com/forms/d/e/1FAIpQLSefrkNNYydNTp-hQwBapGP1lg1uZP8G2ghSE5GSeaNere06Tw/formResponse'
    form_data = {
        "entry.1274867366": name,
        "entry.1546935728": experience,
        "entry.1774645751": rating
    }
    try:
        res = requests.post(form_post_url, data=form_data)
        print(res.content)
        return "‚úÖ Feedback submitted successfully!" if res.status_code == 200 else "‚ùå Failed to submit feedback."
    except Exception as e:
        return f"‚ùå Error submitting feedback: {e}"


system_prompt = f"""
    Hey you are a helpful, user friendly AI assistant, you will help workshop participants with
    useful, real-time information, who is specific to a responding to user queries regarding a meetup happening at ScaleOrange technologies
    Masthan Nagar, Kavuri Hills, Madhapur, Hyderabad, Telangana 500081, India
    About Event
        Build with AI - A Workshop in Collaboration with Google for Developers

        Happening on: Sunday, May 18, 2025 from 10:00 AM IST to 4:00 PM IST

        Hyderabad's developer community is invited to an experiential 1 day workshop on Artificial Intelligence (AI). This hands-on event, hosted in collaboration with Google for Developers, brings together industry experts, innovators, and aspiring AI practitioners.

        Who Should Attend

        - Developers & Engineers
        - Tech Professionals
        - Students & Recent Graduates
        - Entrepreneurs & Product Managers

    Agenda of the event/workshop
        10:00 - 11:00 AM: Hands On Workshop: Automation using Claude and MCP Server
        - Vijender P, Alumnx
        11:00 - 12:00 PM: Hands On Workshop: Agentic AI - Jitendra Gupta (Google
        Developer Expert)
        12:00 - 1:00 PM: Industry Connect Session - Ravi Babu, Apex Cura Healthcare
        1:00 - 2:00 PM: Lunch
        2:00 - 3:00 PM: Hands On Workshop: Build an Event Bot using RAG - Vishvas
        Dubey, TCS
        3:00 - 3:30 PM: Industry Application of AI: Building Multi AI Agents - Surendranath
        Reddy, QAPilot
        3:30 - 4:00 PM: Workshop: Building Multi AI Agents - Mahidhar, NexusHub

    If the user wants to give feedback, act as a feedback bot as well
    collect user feedback in 2 steps: experience summary, and numerical rating (1-5), we already have user's name, so use that.
    Once all data is collected, call the `submit_feedback_to_google_forms` tool.

    Use friendly tone and confirm submissions clearly.

    Also you can use the current time to help users know what session is going on, when lunch is, or how much time is left.
    Don't leave the user with no response, you're there to help them - highly important

    For example
    You are working with a Qdrant vector database containing information about event attendees. Each entry has a 'user_id', 'name', and a 'text_sample' of their resume.

    Rules:
    - Follow the output JSON format
    - Always perform one step at a time and wait for the next input
    - Carefully analyze the user query

    Output JSON format:
    {{
        "step": "string",
        "content": "string",
        "function": "The name of the function if the step is function",
        "input": "The input parameter for the function",
    }}

    Available tools:
        - get_current_time_ist: a tool to access the current time of specific timezone, so that user can know how much time is left for so and so event.
        - submit_feedback_to_google_forms(name="Alice", experience="Great event!", rating=5): a feedbackBot, a tool that collects user feedback in steps of name, experience summary, and numerical rating (1-5), this will ask back to back 3 questions to the user and done, it will not divert in between
        - search_resume_qdrant(query, user_id=None): a tool to search for information in resumes based on the provided query, optionally for a specific user ID
    - If a function needs multiple inputs, return them as a JSON object inside "input". For example: {{ "step": "action", "function": "submit_feedback_to_google_forms", "input": {{ "name": "Ali", "experience": "Loved it!", "rating": 5 }} }}

    Feedback Flow Rules:
        - When user says "I want to give feedback", set `feedback_in_progress` to true and begin the flow.
        - While `feedback_in_progress` is true:
            1. Do not respond with any other information (e.g., resume results).
            2. Collect the following in order:
                - experience and rating
            3. Once these 2 fields are collected:
                - Call `submit_feedback_to_google_forms` with the collected data
                - Clear `feedback_data`
        - Always acknowledge with a friendly message after each step.
        - Never return resume results when `feedback_in_progress` is true, even if the user's name matches a resume entry.

    If the user inputs their own name (e.g., when asking about resumes), always pass their `user_id` in the `search_resume_qdrant` tool so they don't receive results about themselves.

    Rules:
        - Never ever send an error response 500 or related to it, be always positive, you can do it, be in the context of this event.
        - Whatever it be, but don't spread false information, don't make up things when you don't know
    
    Example:
        User query: What is the weather of chicago?
        Output: {{ "step": "plan", "content": "The user is interested in the weather of chicago" }}
        Output: {{ "step": "plan", "content": "From the available tools i should call the get_weather" }}
        Output: {{ "step": "action", "function": "get_weather", "input": "chicago" }}
        Output: {{ "step": "observe", "output": "12 degree celsius" }}
        Output: {{ "step": "output", "content": "The weather for chicago is 12 degree celsius" }}
"""


@app.route("/")
def hello_world():
    res = {'message' : "Hello from BE with Qdrant (Gemini version)"}
    return jsonify(res)

@app.route('/after-login')
def after_login():
    if not google.authorized:
        return redirect(url_for("google.login"))

    resp = google.get("/oauth2/v1/userinfo")
    if not resp.ok:
        return jsonify({"error": "Failed to fetch user info"}), 400

    user_info = resp.json()
    # Optional: create a session, return JWT, etc.

    # Redirect to frontend with user info or token
    return redirect(f"http://localhost:5173/chat?email={user_info['email']}&name={user_info['name']}")

import re

def extract_linkedin_url(text):
    """Extract the first LinkedIn URL from resume text."""
    match = re.search(r"(https?://)?(www\.)?linkedin\.com/in/[^\s)]+", text)
    if match:
        return match.group(0).strip()
    return None

@app.route("/upload", methods=["POST"])
def fileUpload():
    if request.method == "POST":
        print("Upload request received")

        name = request.form.get("name")
        if not name:
            return jsonify({"error": "Name is required"}), 400

        if 'resume' not in request.files:
            return jsonify({"error": "No file found", "data": str(request.files)}), 400

        file = request.files['resume']
        if file.filename == '':
            return jsonify({"error": "Empty filename"}), 400

        filename = secure_filename(file.filename)
        file_path = os.path.join(app.config['UPLOAD_FOLDER'], filename)
        file.save(file_path)

        try:
            with fitz.open(file_path) as doc:
                resume_text = "\n".join(page.get_text() for page in doc)
            if not resume_text.strip():
                return jsonify({"error": "Failed to extract text from resume"}), 500

            print(f"Extracted resume text sample: {resume_text[:200]}...")

            # üîç Extract LinkedIn
            linkedin_url = extract_linkedin_url(resume_text)
            print(f"Extracted LinkedIn URL: {linkedin_url}")

            # üß† Embed and store in Qdrant
            user_id = name.lower().strip().replace(" ", "_")
            embedding_response = genai.embed_content(
                model="gemini-embedding-exp-03-07",
                content=resume_text,
                task_type="retrieval_document",
                output_dimensionality=768
            )
            embedding = embedding_response["embedding"]

            qdrant_client.upsert(
                collection_name=QDRANT_COLLECTION_NAME,
                points=[
                    models.PointStruct(
                        id=int(hashlib.md5(user_id.encode()).hexdigest()[:8], 16),
                        vector=embedding,
                        payload={
                            "user_id": user_id,
                            "name": name,
                            "filename": filename,
                            "text_sample": resume_text[:1000],
                            "upload_time": datetime.now().isoformat(),
                            "linkedin": linkedin_url  # üëâ Store LinkedIn
                        }
                    )
                ]
            )

            print(f"Resume added to Qdrant for {user_id}")
            return jsonify({
                "message": "Resume stored successfully",
                "filename": filename,
                "name": name,
                "user_id": user_id,
                "linkedin": linkedin_url
            })

        except Exception as e:
            import traceback
            traceback.print_exc()
            return jsonify({"error": "Failed to process resume", "details": str(e)}), 500
        finally:
            if os.path.exists(file_path):
                os.remove(file_path)

@app.route("/network")
def network():
    points = qdrant_client.scroll(
        collection_name=QDRANT_COLLECTION_NAME,
        scroll_filter=None,
        limit=1000,
        with_payload=True
    )[0]

    attendees = []
    for point in points:
        payload = point.payload
        if payload:
            attendees.append({
                "user_id": payload.get("user_id"),
                "name": payload.get("name"),
                "linkedin": payload.get("linkedin", None)  # üëà include this
            })

    return jsonify({"attendees": attendees})


@app.route('/check_resume/<username>', methods=['GET'])
def check_resume(username):
    try:
        # Search for any vectors with the username in payload
        search_result = qdrant_client.scroll(
            collection_name="resumes",
            scroll_filter={
                "must": [
                    {"key": "name", "match": {"value": username}}
                ]
            },
            limit=1
        )

        has_uploaded = len(search_result[0]) > 0
        return jsonify({"uploaded": has_uploaded})
    
    except Exception as e:
        print(f"Error checking resume for {username}: {e}")
        return jsonify({"uploaded": False, "error": str(e)}), 500

@app.route("/chat", methods=["POST"])
def chatting():
    
    available_tools = {
        "get_current_time_ist": {
            "fn": get_current_time_ist,
            "description": "a tool to access the current time of specific timezone, so that user can know how much time is left for so and so event"
        },
        "submit_feedback_to_google_forms": {
            "fn": submit_feedback_to_google_forms,
            "description": "a feedbackBot, a tool that collects user feedback inputs of name (user_id), experience summary, and numerical rating (1-5)"
        },
        "search_resume_qdrant": {
            "fn": search_resume_qdrant,
            "description": "Searches for a person's resume information based on the provided query and user ID."
        }
    }

    # Get all attendees for context from Qdrant
    try:
        attendees = get_all_attendees_qdrant()
        attendees_str = ", ".join(attendees)
    except Exception as e:
        print(f"Error getting attendees from Qdrant: {e}")
        attendees_str = "Could not retrieve attendee list"
    
    current_user = request.json.get("user", "").strip()  # üëà Receive current user

    final_prompt = f"""
        {system_prompt}

        The current user interacting is: {current_user}.

        Here is the list of attendees at the event: {attendees_str}. You can use the 'search_resume_qdrant' tool to find information about them if needed. Remember not to disclose personal contact information.
        
        The current user interacting is: {current_user}.
        You already know the current user's name ‚Äî avoid asking it again unless you're unsure.
        If the user wants to submit feedback, collect ONLY the rating (1-5) and a short experience summary.
        Once both are collected, automatically use the `submit_feedback_to_google_forms` tool using:
        - name = {current_user}
        - rating = (from user input)
        - summary = (from user input)
    """

    chat_memory = [
        {"role": "user", "parts": [final_prompt]}
    ]

    user_query = request.json.get("message", "").strip()

    if not user_query:
        return jsonify({"error": "Missing message"}), 400

    chat_memory.append({"role": "model", "parts": ["I'll help workshop participants with information about the event."]})
    chat_memory.append({"role": "user", "parts": [user_query]})

    while True:
        try:
            response = chat_model.generate_content(
                chat_memory,
                generation_config={
                    "response_mime_type": "application/json"
                }
            )

            # Extract and parse the JSON response
            try:
                parsed_output = json.loads(response.text)
                chat_memory.append({"role": "model", "parts": [json.dumps(parsed_output)]})

                if parsed_output.get("step") == "plan":
                    print(f"üß†: {parsed_output.get('content')}")
                    continue

                if parsed_output.get("step") == "action":
                    tool_name = parsed_output.get("function")
                    tool_input = parsed_output.get("input")

                    if available_tools.get(tool_name):
                        tool_fn = available_tools[tool_name]["fn"]
                        if isinstance(tool_input, dict):
                            output = tool_fn(**tool_input)
                        else:
                            output = tool_fn(tool_input)
                        chat_memory.append({"role": "model", "parts": [json.dumps({"step": "observe", "output": output})]})
                        continue

                if parsed_output.get("step") == "output":
                    print(f"ü§ñ: {parsed_output.get('content')}")
                    return jsonify({"message": parsed_output.get("content")})

            except json.JSONDecodeError as e:
                print(f"JSON Decode Error: {e}, Content: {response.text}")
                return jsonify({"error": "Failed to parse AI response"}), 500

        except Exception as e:
            print(f"An unexpected error occurred: {e}")
            return jsonify({"error": "An unexpected error occurred"}), 500

if __name__ == "__main__":
    app.run(debug=True)